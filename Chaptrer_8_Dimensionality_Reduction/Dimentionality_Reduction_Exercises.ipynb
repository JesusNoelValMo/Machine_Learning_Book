{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dimentionality_Reduction_Exercises.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6CLG5S0Rk9H"
      },
      "source": [
        "#Exercise 9.\n",
        "* Exercise: Load the MNIST dataset (introduced in chapter 3) and split it into a training set and a test set (take the first 60,000 instances for training, and the remaining 10,000 for testing).\n",
        "* Train a Random Forest classifier on the dataset and time how long it takes, then evaluate the resulting model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDwcd_6OJJaE"
      },
      "source": [
        "from sklearn.datasets import fetch_openml"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2Ypia6LQXi4"
      },
      "source": [
        "mnist_ = fetch_openml(name=\"mnist_784\", version='active')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SBBFvmOQxrm"
      },
      "source": [
        "X = mnist_[\"data\"]\n",
        "y = mnist_[\"target\"]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E_6oWDqQh9U"
      },
      "source": [
        "from sklearn.ensemble import  RandomForestClassifier\n",
        "random_forest = RandomForestClassifier()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlz3qSnDQqu_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=60000)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF4d7YaJRcM-",
        "outputId": "73ae2a70-2868-4931-84de-2e5f86fc0e70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import time\n",
        "t0 = time.time()\n",
        "random_forest.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "print(f'Training time: {t1-t0}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time: 36.04145836830139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1uIALjxStdX"
      },
      "source": [
        "* Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVydfnlpR4Pe",
        "outputId": "ef757080-3fd9-4f42-9c9e-1f9fedc7c37b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(random_forest.predict(X_test), y_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9679"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJvuanu1TK_2"
      },
      "source": [
        "* Let's try reducing the dimentionality "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tVxlm3ZTQ8y"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "PCA_transformer = PCA(n_components=0.95)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3rFzggtTxqu"
      },
      "source": [
        "X_PCA_transformed = PCA_transformer.fit_transform(X_train)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h17j0F3oUTG2",
        "outputId": "c5bcbc02-d649-49f0-bf2f-e233f9b0c24a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t0 = time.time()\n",
        "random_forest.fit(X_PCA_transformed, y_train)\n",
        "t1 = time.time()\n",
        "print(f'Training time: {t1-t0}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time: 94.6192057132721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV8Ey2f2btCb"
      },
      "source": [
        "* It took much longer to train\n",
        "* Let's evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSGKoQRAa-O8",
        "outputId": "e99810be-3649-4303-f7e2-20d8d20d13f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test_reduced = PCA_transformer.transform(X_test)\n",
        "accuracy_score(random_forest.predict(X_test_reduced), y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9478"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcxGODn2bQxp"
      },
      "source": [
        "* Let's Try a softmax classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3sdmOghbPfU"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log_clf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=42)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d24eU62Eceb8",
        "outputId": "f1fd73c9-f1a0-4ebc-ec8a-81307866c94c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t0 = time.time()\n",
        "log_clf.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "print(f'Training time: {t1-t0}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time: 28.88332223892212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pheiom6cmST",
        "outputId": "b0a0bb8c-b4ae-4f86-d834-831c58d4fb76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accuracy_score(log_clf.predict(X_test), y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9207"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paXfuInwcwNr",
        "outputId": "88dff1e9-793a-4452-b2d3-92bf1fe732c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t0 = time.time()\n",
        "log_clf.fit(X_PCA_transformed, y_train)\n",
        "t1 = time.time()\n",
        "print(f'Training time: {t1-t0}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time: 9.273509502410889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwoej-77c8XD",
        "outputId": "4fad5b67-ea18-4b6c-99c1-3db43c52a6bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accuracy_score(log_clf.predict(X_test_reduced), y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9146"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFCOaDtVc_UL"
      },
      "source": [
        "* For the Softmax model the training time was reduced by about 3 times and the accuracy is slightly the same."
      ]
    }
  ]
}